# ğŸ—£ï¸Dialogue Summarization
## **[HighFive]** ì–´ë ¤ì›Œë„ í˜ë“¤ì–´ë„ ì†Œí†µí•˜ë©° ë¬¸ì œí•´ê²°í•˜ì!

| ![ê¹€ì¢…í™”](https://avatars.githubusercontent.com/u/221108223?v=4) | ![ë°•ì¤€ì˜](https://avatars.githubusercontent.com/u/221072284?v=4) | ![ê¶Œíš¨ì£¼](https://avatars.githubusercontent.com/u/13392737?v=4) | ![ê¶Œë¬¸ì§„](https://avatars.githubusercontent.com/u/89570502?v=4) | ![ìµœë³´ê²½](https://avatars.githubusercontent.com/u/110219144?v=4) |
| :--------------------------------------------------------------: | :--------------------------------------------------------------: | :--------------------------------------------------------------: | :--------------------------------------------------------------: | :--------------------------------------------------------------: |
|            [ê¹€ì¢…í™”](https://github.com/JHKIM-ItG)             |            [ë°•ì¤€ì˜](https://github.com/juny79)             |            [ê¶Œíš¨ì£¼](https://github.com/hopeplanting)             |            [ê¶Œë¬¸ì§„](https://github.com/moongs95)             |            [ìµœë³´ê²½](https://github.com/bekky1016)             |
|                            íŒ€ì¥, ëª¨ë¸ì„¤ê³„ ë° í…ŒìŠ¤íŠ¸                             |                            ëª¨ë¸ ì„¤ê³„ ë° í…ŒìŠ¤íŠ¸                             |                            ëª¨ë¸ ì„¤ê³„ ë° í…ŒìŠ¤íŠ¸                             |                            EDA ë° ì „ì²˜ë¦¬                             |                            EDA ë° ì „ì²˜ë¦¬                             |
## 0. Overview
### Environment
- Python 3.10  
- PyTorch / Transformers / ROUGE / pandas  
- QLoRA(4bit) + BitsAndBytes  
- ì‹¤í—˜ ê´€ë¦¬: WandB  
- Git ë²„ì „ê´€ë¦¬  
- seed ê³ ì •ìœ¼ë¡œ ì¬í˜„ì„± í™•ë³´  

### Requirements
- 10.7B ëª¨ë¸ì„ GPU ë©”ëª¨ë¦¬ ë‚´ì—ì„œ í•™ìŠµí•˜ê¸° ìœ„í•´ **4bit ì–‘ìí™”**
- Encoder/Decoder max length ì¡°ì • í•„ìˆ˜
- Special tokens ì¶”ê°€ (`#Person#`, `#PhoneNumber#`, `#Address#`, â€¦)

## 1. Competiton Info

### Overview

- ì¼ìƒ ë©€í‹°í„´ ëŒ€í™”ë¥¼ 2â€“3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” **Dialogue Summarization** ê³¼ì œ  
- í•™êµÂ·ì§ì¥Â·ì—¬ê°€Â·ìƒë‹´Â·ì‡¼í•‘ ë“± ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬  
- ê¸°ê°„: **2025.11.27 ~ 2025.12.10**

### Timeline
- **Start:** 2025-11-27  
- **Final Submission:** 2025-12-10 

## 2. Components

### Directory

- _Insert your directory structure_

e.g.
```
â”œâ”€â”€ code
â”‚   â”œâ”€â”€ jupyter_notebooks
â”‚   â”‚   â””â”€â”€ model_train.ipynb
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ pdf
â”‚   â”‚   â””â”€â”€ (Template) [íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤] Upstage AI Lab 1ê¸°_ê·¸ë£¹ ìŠ¤í„°ë”” .pptx
â”‚   â””â”€â”€ paper
â””â”€â”€ input
    â””â”€â”€ data
        â”œâ”€â”€ eval
        â””â”€â”€ train
```

## 3. Data descrption

### Dataset overview

- Train: **12,457**, Dev: **499**, Test: **250**
- ê²°ì¸¡ì¹˜ ì—†ìŒ â†’ ì¶”ê°€ ì •ì œ ë¶ˆí•„ìš”  
- ëŒ€í™” ê¸¸ì´: í‰ê·  **406 chars**, ìµœëŒ€ **2165 chars**  
- ìš”ì•½ ê¸¸ì´: í‰ê·  **20â€“30 tokens**  
- í„´ ìˆ˜: í‰ê·  **9.47í„´**, ìµœëŒ€ **59í„´** â†’ ì¼ë¶€ ë¡±ì»¨í…ìŠ¤íŠ¸ ì¡´ì¬  

### EDA

### âœ” ì¹´í…Œê³ ë¦¬ ë¶„í¬
- ê°€ì¥ ë†’ì€ ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨ë„ **1.04%**  
â†’ ë¼ë²¨ì€ ëª¨ë¸ ì„±ëŠ¥ì— **ê±°ì˜ ì˜í–¥ ì—†ìŒ**

### âœ” íŠ¹ìˆ˜ë¬¸ìÂ·ë…¸ì´ì¦ˆ ì œê±°
- `<br>`, HTML escape, ê´„í˜¸ ë‚´ ì§€ì‹œë¬¸ ë“± ì œê±°  
â†’ **KoBART ê¸°ì¤€ +0.5 ROUGE ìƒìŠ¹**

### âœ” ëŒ€í™” filler ì œê±°
- "ì•„, ì–´, ìŒ, ê·¼ë°, ê·¸ëƒ¥â€¦"  
- OKT/TF-IDF ì‹¤íŒ¨ â†’ ê·œì¹™ ê¸°ë°˜ ì‚¬ì „ êµ¬ì¶•  
â†’ **+0.93 ROUGE ì¶”ê°€ ìƒìŠ¹**

### Data Processing

- íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” & ë¶ˆí•„ìš” í† í° ì‚­ì œ  
- êµ¬ì–´ì²´ filler ì œê±°  
- Special Tokens í™•ì¥ (`#Person#`, `#PhoneNumber#` ë“±)  

## 4. Modeling

### Model descrition
## 1) KoBART Baseline ê°œì„ 
- encoder_max_len ì¦ê°€  
- decoder_max_len ì¦ê°€  
- label smoothing=0.1  
- num_beams=3â€“4  
- ì „ì²˜ë¦¬ ìµœì í™”ë¡œ **ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ**


---

## 2) SOLAR-10.7B-Instruct (QLoRA)
- 4bit ì–‘ìí™” + LoRA r=8/16  
- max_seq_length=1024  
- SFTTrainer í™œìš©  
- 24GB VRAMì—ì„œë„ í•™ìŠµ ê°€ëŠ¥  
- Base FT ì ìˆ˜ **44.54 â†’ inference tuningìœ¼ë¡œ 51.69**  
- ì¶”ê°€ ì¬í•™ìŠµ ëª¨ë¸ **51.77ì **

---

## 3) Inference Optimization
- í”„ë¡¬í”„íŠ¸ 4ì¢… ì‹¤í—˜  
- Beam search / repetition penalty / length penalty ê·¸ë¦¬ë“œì„œì¹˜  
- í›„ì²˜ë¦¬ë¡œ ë¯¸ì™„ì„± ë¬¸ì¥ ì œê±°  

### Modeling Process
- ì „ì²˜ë¦¬ â†’ tokenizer í™•ì¥ â†’ KoBART baseline â†’ SOLAR FT â†’ inference íŠœë‹ â†’ ensemble(KoBART + SOLAR)

- WandBë¡œ ì‹¤í—˜ ê´€ë¦¬

## 5. Result

### Leader Board

**ìµœì¢… ì œì¶œ ì ìˆ˜: 51.4457**

KoBART baseline ëŒ€ë¹„ í° í­ ê°œì„ 

### Presentation

- ë°œí‘œìë£Œ(PDF): *ì²¨ë¶€ ì˜ˆì •*

## etc

### Meeting Log

- Notion ìë™ ë¡œê·¸  
- Slack ê¸°ë¡ ê³µìœ   
- ë§¤ì¼ Zoom íšŒì˜ ì§„í–‰  

### Reference

- Dialogue Summarization ë…¼ë¬¸  
- Upstage SOLAR HuggingFace Docs  
- Solar Prompting Handbook  
